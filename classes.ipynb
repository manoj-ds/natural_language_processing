{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "finite-graphic",
   "metadata": {},
   "source": [
    "# <Center>Word2Vec (Embeddings)</Center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "standing-burst",
   "metadata": {},
   "source": [
    "# <Center>NLP Class 1 (15th May)</Center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "applied-lending",
   "metadata": {},
   "source": [
    "1. Frequency Based Embeddings.\n",
    "2. Prediction based Embeddings. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cardiac-array",
   "metadata": {},
   "source": [
    "**Frequency** : Doc, Token, Corpus, Vocablar <br>\n",
    "**Doc**: lowest level of granularity (Each tweet is a document). Document is a collection of words.\n",
    "**Token**: word\n",
    "**Corpus** : Entire dataset is call Corpus\n",
    "**Vocab**: Unique Tokens in the document."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protected-maple",
   "metadata": {},
   "source": [
    "Document Term Matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "considered-wagner",
   "metadata": {},
   "source": [
    "Drawbaks of term matrix\n",
    "1. No context is taken care\n",
    "2. Not frequency is taken care\n",
    "3. Not sequence is defined.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "organized-consumer",
   "metadata": {},
   "source": [
    "## What is bag of words?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wireless-issue",
   "metadata": {},
   "source": [
    "Document is dimentition<br>\n",
    "jkard similarity <br>\n",
    "hamming distance for binary vectors "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "superb-eating",
   "metadata": {},
   "source": [
    "Frequncy of the word\n",
    "what is TFidf vectorizer and why it's used\n",
    "\n",
    "why stop words are removed "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "naughty-native",
   "metadata": {},
   "source": [
    "# <Center>NLP Class 2 (16th May)</Center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tender-owner",
   "metadata": {},
   "source": [
    "Problem with **Bag of words and Count vectroizer** \n",
    "* Context missing\n",
    "* Sequence is missing\n",
    "* Grammer \n",
    "* Dimentionality (Voc is large and document is small then matrix can be very space)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "referenced-tunnel",
   "metadata": {},
   "source": [
    "How to handle space matrix<br>\n",
    "* Stopword removal<br>\n",
    "* lemitization/stemming\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "golden-laptop",
   "metadata": {},
   "source": [
    "* The goal of both stemming and lemmatization is to reduce inflectional forms and sometimes derivationally related forms of a word to a common base form. For instance:\n",
    "\n",
    "-> am, are, is $\\Rightarrow$ be <br>\n",
    "-> car, cars, car's, cars' $\\Rightarrow$ car"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "multiple-bradley",
   "metadata": {},
   "source": [
    "- Stopwords are removed from sentence doesn't matter in frequency based embeddings.\n",
    "- lemitization is used to remove the sparceness in  the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "statutory-cause",
   "metadata": {},
   "source": [
    "### Stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "statistical-convert",
   "metadata": {},
   "source": [
    "* It's also use to get the root word with the help of an algorithem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "technical-portuguese",
   "metadata": {},
   "source": [
    "### TFIDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "naval-crystal",
   "metadata": {},
   "source": [
    "* TF -> term frequency\n",
    "* IDF -> Inverse Document Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supported-kansas",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
